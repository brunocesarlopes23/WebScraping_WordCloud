{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPs5NHXkuQKJzxZZAD4qgrk"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **WebScraping_and_wordcloud_news**\n"],"metadata":{"id":"MJp4CWnzoYHt"}},{"cell_type":"code","source":["  pip install wordcloud\n","  pip install nltk\n","  pip install feedparser"],"metadata":{"id":"FsQOy8Fvsq2F"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":48,"metadata":{"id":"cmeHx-YNogv-","executionInfo":{"status":"ok","timestamp":1675871047838,"user_tz":180,"elapsed":498,"user":{"displayName":"Bruno Lopes","userId":"15548270257276934101"}}},"outputs":[],"source":["#Criando função webscrapping de rss de notícias\n","def wordcloudnews_rss (x):\n","  '''Inserir  URL RSS entre aspas\n","  A saída lhe exporta uma wordcloud.png e um arquivo csv com as palavras e sua respectivas frequencias'''\n","  \n","  import pandas as pd\n","  import feedparser as ps\n","  import nltk \n","  import wordcloud \n","  nltk.download('popular') #Download dos pack de palavras\n","  nltk.download('punkt') #download pack\n","\n","  _x = ps.parse(x)\n","\n","\n","  #Selecionando Title _x\n","  news_title_x=[]\n","  for post in _x.entries:\n","    news_title_x.append(post['title'])\n","\n","  #Bag Of Words\n","  #Separando em palavras x\n","  from nltk import word_tokenize\n","  text_x=''\n","  for n in news_title_x:\n","      text_x=text_x+n.lower()\n","  token_x=word_tokenize(text_x)\n","  \n","\n","\n","\n","  #Stop Words x\n","  #Retirando palavras sem importância\n","  from nltk.corpus import stopwords\n","  stop_words = list(stopwords.words('english')) #lista das stop words\n","  #Loop para gerar lista sem as stop words\n","  token_x_stop_filter=[]\n","  for t in token_x:\n","      if t in stop_words:\n","          continue\n","      else:\n","          token_x_stop_filter.append(t)\n","  \n","\n","  #Stemming x\n","  #Diminuindo para os radicais de cada palavra\n","  from nltk.stem import PorterStemmer\n","  pst = PorterStemmer()\n","  token_x_stop_stem_filter=[]\n","  for s in token_cnn_stop_filter:\n","      token_x_stop_stem_filter.append(pst.stem(s))\n","\n","  \n","\n","  #CNN - Filtro de pontuação e palavras com dois caracteres\n","  token_x_stop_stem_punctuation_filter=[]\n","  for t in token_x_stop_stem_filter:\n","      if len(t)<3:\n","          continue\n","      else:\n","          token_x_stop_stem_punctuation_filter.append(t)\n","\n","\n","  #TF\n","  from nltk.probability import FreqDist\n","  fdist = FreqDist(bagofwords)\n","  wordsandfreq=dict(fdist)\n","\n","  #df word and freq to csv\n","  serie_words=pd.DataFrame(columns=['word','freq'])\n","  serie_words['word']=wordsandfreq.keys()\n","  serie_words['freq']=wordsandfreq.values()\n","  forexternal=serie_words.sort_values(['freq'],ascending=False).reset_index(drop=True)\n","  forexternal.to_csv('forexternal.csv',index=False)\n","\n","  #bagofwordslist to text\n","  text=''\n","  for t in bagofwords:\n","    text=text+' '+t\n","\n","  #Gerando nuvem de palavras  \n","  from wordcloud import WordCloud\n","  wordcloud=WordCloud().generate_from_text(text)\n","  wordcloud.to_file(\"news_wordcloud.png\")\n","\n"]},{"cell_type":"code","source":["wordcloudnews_rss('http://rss.cnn.com/rss/edition.rss')"],"metadata":{"id":"H5N1hqe9oNUj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"67aZ-7Nlkfxo"},"execution_count":null,"outputs":[]}]}